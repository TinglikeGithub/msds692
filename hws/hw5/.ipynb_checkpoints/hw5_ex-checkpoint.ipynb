{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_title(text):\n",
    "    \"\"\"\n",
    "    Given text returns title and the rest of the article.\n",
    "\n",
    "    Split the test by \"\\n\" and assume that the first element is the title\n",
    "    \"\"\"\n",
    "    ## YOUR CODE HERE\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "    title = []\n",
    "    body = []\n",
    "    for line in lines:\n",
    "        line = line.split(' ')\n",
    "        title.append(line[0])\n",
    "        body.append(line[1:])\n",
    "    return title, body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['iraq', 'official'],\n",
       " [['use', 'members', 'each', 'area', 'found,', ''],\n",
       "  ['sunday', 'place', 'go', 'based']])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"iraq use members each area found, \\nofficial sunday place go based\"\n",
    "split_title(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS = frozenset([\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "    \"yourselves\"])\n",
    "\n",
    "\n",
    "def load_glove(filename):\n",
    "    \"\"\"\n",
    "    Read all lines from the indicated file and return a dictionary\n",
    "    mapping word:vector where vectors are of numpy `array` type.\n",
    "    GloVe file lines are of the form:\n",
    "\n",
    "    the 0.418 0.24968 -0.41242 0.1217 ...\n",
    "\n",
    "    So split each line on spaces into a list; the first element is the word\n",
    "    and the remaining elements represent factor components. The length of the vector\n",
    "    should not matter; read vectors of any length.\n",
    "\n",
    "    ignore stopwords\n",
    "    \"\"\"\n",
    "    # filename = \"test_glove.txt\"\n",
    "    ## YOUR CODE HERE\n",
    "    glove_dict = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.split(' ')\n",
    "            title = line[0]\n",
    "            if title in ENGLISH_STOP_WORDS:\n",
    "                continue\n",
    "            vector = line[1:]\n",
    "            glove_dict[title]=vector\n",
    "    return glove_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "['0.080226', '0.12737', '-0.14312', '0.22288', '-0.22367', '-0.1141', '-0.045303', '0.028988', '-0.036847', '-0.96226', '0.091978', '-0.19067', '-0.068613', '0.22368', '0.27402', '0.5474', '-0.12593', '0.56245', '-0.014827', '-0.15535', '0.16828', '-0.59398', '0.089404', '-0.33408', '-0.067466', '-0.021859', '0.33213', '0.090294', '-0.15112', '-0.1997', '0.040152', '0.034056', '0.27067', '0.57608', '-1.522', '-0.20171', '0.081906', '0.26662', '-0.304', '0.085508', '0.21813', '0.26046', '0.24974', '0.11273', '-0.2574', '0.11913', '0.30533', '0.01139', '-0.23501', '-0.083045', '0.018821', '0.025827', '-0.084135', '0.023554', '-0.23713', '0.49462', '0.032241', '-0.078873', '0.2167', '-0.18541', '-0.15104', '0.063338', '0.11729', '-0.17788', '-0.34219', '-0.68552', '0.3978', '0.042104', '0.044774', '-0.26269', '0.054141', '0.076898', '0.16915', '-0.10339', '-0.15563', '0.26022', '-0.10354', '0.06517', '0.012187', '0.30074', '-0.040981', '-0.21038', '-0.42154', '0.73314', '-0.14972', '-0.088901', '-0.72531', '-0.20526', '0.47737', '0.2966', '-0.22001', '-0.37429', '-0.23581', '-0.13207', '-0.21047', '-0.097034', '-0.069957', '-0.12271', '-0.59522', '-0.35717', '0.3683', '0.33519', '0.026385', '0.31747', '0.6329', '0.54644', '0.37958', '-0.067675', '0.038144', '-0.030398', '-0.27472', '-0.13935', '-0.010643', '0.0090993', '0.31261', '0.31634', '-0.16817', '-0.10701', '0.43126', '-0.76809', '-0.20878', '-0.28735', '0.18837', '-0.16581', '-0.34741', '0.3035', '-0.032351', '-0.28956', '-0.18479', '0.07081', '-0.00056177', '0.33956', '0.165', '0.389', '-0.28522', '0.01858', '-0.20886', '-0.25227', '0.41775', '0.33215', '-0.24561', '0.23187', '0.043666', '-0.090464', '-0.50183', '0.11522', '0.13608', '-0.0065607', '-0.11273', '0.12374', '0.77992', '0.044053', '0.12886', '0.020302', '0.49975', '-0.098006', '0.30465', '0.11908', '0.25411', '-0.14754', '0.17048', '-0.20604', '-0.032226', '-0.1437', '-0.11289', '0.45677', '-0.047363', '-0.28717', '-0.034245', '-0.60062', '0.006219', '-0.046897', '-0.31965', '-0.014641', '0.14143', '0.13026', '0.1467', '0.42821', '-0.078368', '0.63917', '0.34303', '0.5227', '0.35277', '0.0092699', '0.067812', '0.51897', '-0.5373', '-0.18323', '-0.48755', '0.068509', '-0.11857', '0.28638', '0.01371', '0.24083', '0.3722', '-0.14577', '0.30723', '0.036606', '-0.20725', '0.42598', '0.88768', '-0.15485', '-0.51061', '-0.099348', '0.16422', '-0.38223', '-0.27255', '-0.55674', '-0.18873', '0.11847', '-0.066515', '0.34787', '-0.11157', '-0.2456', '0.073037', '-0.35315', '0.0039106', '-0.7307', '0.56379', '-0.017985', '1.3699', '-0.079459', '-0.18661', '0.34235', '-0.17146', '0.14469', '0.35795', '-0.4568', '0.16418', '0.12416', '0.11981', '0.0077406', '0.37955', '-0.47641', '1.1066', '-0.093417', '0.42644', '0.056871', '0.36307', '-0.067684', '-0.043779', '-0.15915', '-0.032036', '0.05827', '0.71841', '-0.08038', '0.030715', '0.14921', '0.25231', '0.44098', '-0.078268', '0.046181', '0.10879', '-0.016677', '0.48179', '0.035352', '0.31051', '-0.34154', '-0.1075', '0.24113', '0.2256', '0.033662', '0.063145', '0.15471', '0.1507', '-0.12934', '0.091715', '-0.25953', '0.22054', '-0.62111', '-0.1004', '-0.1967', '0.25563', '0.20282', '0.21542', '0.1479', '-2.3197', '0.17394', '0.53476', '0.20657', '-0.027128', '-0.044831', '0.47131', '-0.074296', '-0.19242', '-0.46027', '-0.35856', '0.14238', '-0.015903', '0.051805', '-0.54182', '-0.054784', '-0.075428', '0.27443', '-0.073088', '0.47233', '-0.14494', '-0.28735', '-0.69429', '0.024827\\n']\n"
     ]
    }
   ],
   "source": [
    "glove_dict = load_glove(\"test_glove.txt\")\n",
    "print(len(glove_dict))\n",
    "print(glove_dict['sunday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
